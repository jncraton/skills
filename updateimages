#!/usr/bin/env python3
import pathlib
import re
import csv


def get_wikimedia_images(content):
    pattern = r"!\[([^\]]*)\]\((https://upload\.wikimedia\.org/wikipedia/commons/[^\s\)]+)\)"
    return re.findall(pattern, content)


def scan_md_files(root):
    matches = []
    for path in root.rglob("*.md"):
        if path.is_dir():
            continue
        try:
            content = path.read_text(encoding="utf-8")
            matches.extend(get_wikimedia_images(content))
        except (PermissionError, UnicodeDecodeError):
            continue
    return matches


def get_full_url(url):
    if "/thumb/" in url:
        return url.replace("/thumb/", "/").rsplit("/", 1)[0]
    return url


def write_tsv(data, filename):
    dedup = {}
    counts = {}
    for alt, url in data:
        full_url = get_full_url(url)
        if full_url not in dedup:
            dedup[full_url] = {}
            counts[full_url] = 0
        if alt:
            dedup[full_url][alt.lower()] = alt
        counts[full_url] += 1

    rows = []
    for url in dedup:
        alts = ",".join(sorted(dedup[url].values()))
        rows.append((counts[url], url, alts))

    rows.sort(key=lambda x: x[0], reverse=True)

    with open(filename, "w", newline="", encoding="utf-8") as f:
        writer = csv.writer(f, delimiter="\t")
        writer.writerow(["uses", "url", "alt_text"])
        for count, url, alts in rows:
            writer.writerow([count, url, alts])


def main():
    home = pathlib.Path.home()
    images = scan_md_files(home)
    write_tsv(images, "images.tsv")


if __name__ == "__main__":
    main()
